{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#import nltk\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n",
      "punctuation =  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('..', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('..', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "filenames_stop_words = sorted(glob(op.join('..','data','english.stop')))\n",
    "\n",
    "\n",
    "stop_words_list = [open(f).read() for f in filenames_stop_words][0].split()\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))\n",
    "print(\"punctuation = \", string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess\n",
    "\n",
    "def text_process(texts, stem = False, tag = False):\n",
    "    \"\"\"\n",
    "        Takes in a list of texts, then performs the following:\n",
    "        1. Remove all punctuation for each text\n",
    "        2. Remove all stopwords for each text\n",
    "        3. Returns the cleaned texts\n",
    "        \n",
    "        if stem == True, change each word to its stem.\n",
    "        if tag == True, we'll keep only noun, adverbs, verbs and adjectives.\n",
    "    \"\"\"\n",
    "    cleaned_texts = []\n",
    "    keep_cat = ['NN','ADV','VB','JJ']\n",
    "    for text in texts :\n",
    "        list_text = []\n",
    "        # Check characters to see if they are in punctuation\n",
    "        nopunc = [char for char in text if char not in string.punctuation]\n",
    "    \n",
    "        # Join the characters again to form the string.\n",
    "        nopunc = ''.join(nopunc)\n",
    "    \n",
    "        # Now just remove any stopwords and stem words\n",
    "        list_words = nopunc.split()\n",
    "        if stem == False :\n",
    "            if tag == False :\n",
    "                list_text = [word for word in list_words if word.lower() not in stop_words_list] #Question 2\n",
    "            else :\n",
    "                for word in nopunc.split() :\n",
    "                    print(pos_tag([stemmer.stem(word)]))\n",
    "                list_text = [word for word in list_words if word.lower() not in stop_words_list] #Question 4\n",
    "                #print(list_text)\n",
    "        else :\n",
    "            if tag == False :\n",
    "                list_text = [stemmer.stem(word) for word in list_words if word.lower() not in stop_words_list] #Question 3\n",
    "            else :\n",
    "                list_text = [stemmer.stem(word) for word in list_words if (word.lower() not in stop_words_list and pos_tag([word])[0][1] not in keep_cat)] #Question 3\n",
    "                \n",
    "                    \n",
    "        new_text = ' '.join(list_text)\n",
    "        cleaned_texts.append(new_text)\n",
    "       \n",
    "    return cleaned_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_processed = text_process(texts, stem = False, tag = False)\n",
    "X = vectorizer.fit_transform(texts_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_processed_stem = text_process(texts, stem = True, tag = False)\n",
    "X_stem = vectorizer.fit_transform(texts_processed_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_processed_stem_tag = text_process(texts, stem = True, tag = True)\n",
    "X_stem_tag = vectorizer.fit_transform(texts_processed_stem_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 47026)\n",
      "(2000, 31375)\n",
      "(2000, 12700)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(X_stem.shape)\n",
    "print(X_stem_tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Naive Bayesien with cross validation 5-folds: \n",
      "Mean accuracy with no stem and no tag = {acc} % 80.74999999999999\n",
      "Mean accuracy with stem and no tag = {acc} % 80.4\n",
      "Mean accuracy with stem and tag = {acc} % 76.55000000000001\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayesien\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "print(\"Testing Naive Bayesien with cross validation 5-folds: \")\n",
    " \n",
    "\n",
    "clf = MultinomialNB()\n",
    "\n",
    "print(\"Mean accuracy with no stem and no tag = {acc} %\", 100*cross_val_score(clf,X,y, cv = 5).mean())\n",
    "    \n",
    "print(\"Mean accuracy with stem and no tag = {acc} %\", 100*cross_val_score(clf,X_stem,y, cv = 5).mean())\n",
    "   \n",
    "print(\"Mean accuracy with stem and tag = {acc} %\", 100*cross_val_score(clf,X_stem_tag,y, cv = 5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Linear SVC : \n",
      "0.825\n",
      "0.8240000000000001\n",
      "0.8225\n",
      "0.8215\n",
      "0.8220000000000001\n",
      "0.8164999999999999\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "print(\"Testing Linear SVC : \")\n",
    "\n",
    "\n",
    "\n",
    "for c in [0.1, 0.5, 1, 1.5, 3] :\n",
    "    clf = LinearSVC(C = c)\n",
    "    print(cross_val_score(clf,X,y, cv = 5).mean())\n",
    "\n",
    "clf = LinearSVC(C = 0.1)\n",
    "print(cross_val_score(clf,X_stem,y, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LogisticRegression : \n",
      "0.8305\n",
      "0.825\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "print(\"Testing LogisticRegression : \")\n",
    "clf = LogisticRegression()\n",
    "print(cross_val_score(clf,X,y, cv = 5).mean())\n",
    "print(cross_val_score(clf,X_stem,y, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
